{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## BBM418 Computer Vision Lab. Assignment 3.\n",
    "## by Mehmet Giray Nacakci, 21989009.\n",
    "<br>\n",
    "\n",
    "## The ../Micro_Organism/ folder containing image sets should be put in the same location as\n",
    "## /code folder, so that /code/part_1.ipynb can read the images.\n",
    "<br>\n",
    "\n",
    "## After running the \"Initialization Code\" section,\n",
    "## You can choose a model to Train and Display Results in the next section.\n",
    "## Results are printed in this notebook, and plots are saved to ../results/ folder.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# INITIALISATION CODE\n",
    "\n",
    "## Loading Libraries, Defining Functions, Pre-Processing the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Python version 3.11 \"\"\"\n",
    "\"\"\" PyTorch 2.0.1 \"\"\"\n",
    "import torch  # 2.0.1\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "root = \"../Micro_Organism/\"\n",
    "classes_folders = os.listdir(root)\n",
    "classes_folders = [i for i in classes_folders if i != \".DS_Store\"]   # Fix for macOS\n",
    "\n",
    "classes_to_indices = {key: index for index, key in enumerate(classes_folders)}  # enumerated such as 0, 1, ..., 7\n",
    "\n",
    "# Dataset Partitions\n",
    "train_images_files, validation_images_files, test_images_files = [], [], []\n",
    "train_images, validation_images, test_images = [], [], []\n",
    "train_labels, validation_labels, test_labels = [], [], []  # enumerated as a number such as 0, 1, ..., 7\n",
    "\n",
    "# For plotting the results\n",
    "training_loss_array = []\n",
    "training_accuracy_array = []\n",
    "validation_loss_array = []\n",
    "validation_accuracy_array = []\n",
    "\n",
    "\n",
    "def show_an_image_from_each_class(image_categories):\n",
    "\n",
    "    pyplot.figure(figsize=(12, 8))\n",
    "\n",
    "    for i, class_ in enumerate(image_categories):\n",
    "        class_path = \"../Micro_Organism/\" + class_\n",
    "        if \"DS_Store\" in class_path:\n",
    "            continue   # Fix for macOS\n",
    "\n",
    "        images_in_folder = os.listdir(class_path)\n",
    "        first_image = Image.open(class_path + '/' + images_in_folder[0])\n",
    "        pyplot.subplot(2, 4, i + 1)\n",
    "        pyplot.imshow(first_image)\n",
    "        pyplot.title(class_)\n",
    "        pyplot.axis('off')\n",
    "\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "print(\"\\nExamples of Dataset Classes:\\n\")\n",
    "show_an_image_from_each_class(classes_folders)\n",
    "\n",
    "\n",
    "def pre_process_image(img):\n",
    "    # some images are read as a single channel or 4 channels (png), fix it to 3 channels\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "    # high-quality resizing.\n",
    "    img = img.resize((224, 224), resample=Image.LANCZOS, reducing_gap=3.0)\n",
    "    # Resizing the images without an antialiasing filter allows the CNN to observe the images in their original form,\n",
    "    # preserving the fine-grained details and textures. \"\"\"\n",
    "\n",
    "    img = np.array(img, dtype=np.float32) / 255.0  # normalize\n",
    "    img = np.transpose(img, (2, 0, 1))  # size: (3 x height x width) to be fed into CNN\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_and_preprocess_dataset():\n",
    "\n",
    "    # Collect image files paths\n",
    "    for i, class_ in enumerate(classes_folders):\n",
    "        class_path = \"../Micro_Organism/\" + class_\n",
    "        if \"DS_Store\" in class_path:\n",
    "            continue   # Fix for macOS\n",
    "\n",
    "        \"\"\" Since the categories in the dataset has 72, 75, 75 , 76, 85, 86, 152, 168 images,\n",
    "        for balance and homogeneity (for less bias towards any class);\n",
    "        each class is partitioned as  50 train,  10 validation,  10 test  images. \"\"\"\n",
    "        images_in_folder = os.listdir(class_path)[0:70]  # use only 70 images\n",
    "        random.shuffle(images_in_folder)\n",
    "        for j, image in enumerate(images_in_folder):\n",
    "            img_name = class_path + '/' + images_in_folder[j]\n",
    "\n",
    "            if j > 59:\n",
    "                test_images_files.append(img_name)\n",
    "            elif j > 49:\n",
    "                validation_images_files.append(img_name)\n",
    "            else:\n",
    "                train_images_files.append(img_name)\n",
    "\n",
    "    # shuffle, such that batches almost have homogenous many images of each class\n",
    "    random.shuffle(train_images_files)\n",
    "    random.shuffle(validation_images_files)\n",
    "    random.shuffle(test_images_files)\n",
    "\n",
    "    # LOAD AND PRE-PROCESS Images\n",
    "\n",
    "    for image_path in train_images_files:\n",
    "        train_images.append(pre_process_image(Image.open(image_path)))\n",
    "\n",
    "        class_no = classes_to_indices.get(image_path.split('/')[-2])\n",
    "        train_labels.append(class_no)\n",
    "\n",
    "    for image_path in validation_images_files:\n",
    "        validation_images.append(pre_process_image(Image.open(image_path)))\n",
    "\n",
    "        class_no = classes_to_indices.get(image_path.split('/')[-2])\n",
    "        validation_labels.append(class_no)\n",
    "\n",
    "    for image_path in test_images_files:\n",
    "        test_images.append(pre_process_image(Image.open(image_path)))\n",
    "\n",
    "        class_no = classes_to_indices.get(image_path.split('/')[-2])\n",
    "        test_labels.append(class_no)\n",
    "\n",
    "\n",
    "read_and_preprocess_dataset()\n",
    "\n",
    "# feed dataset partitions to PyTorch\n",
    "# _images_tensor sizes: (dataset partition size x 3 x height x width)\n",
    "\n",
    "training_images_tensor = torch.stack([torch.from_numpy(img) for img in train_images])\n",
    "training_labels_tensor = torch.tensor(train_labels)\n",
    "validation_images_tensor = torch.stack([torch.from_numpy(img) for img in validation_images])\n",
    "validation_labels_tensor = torch.tensor(validation_labels)\n",
    "test_images_tensor = torch.stack([torch.from_numpy(img) for img in test_images])\n",
    "test_labels_tensor = torch.tensor(test_labels)\n",
    "\n",
    "print(\"\\nDataset pre-processed.\")\n",
    "\n",
    "\n",
    "def draw_results_plots(model_no, model_title):\n",
    "    results_plot = pyplot.figure(figsize=(12, 8))\n",
    "    pyplot.title(label=model_title, loc=\"center\", y=1.0, fontsize=16, pad=35)\n",
    "    pyplot.axis('off')\n",
    "\n",
    "    \"\"\" Training and Validation LOSS Plot \"\"\"\n",
    "    results_plot.add_subplot(1, 2, 1)\n",
    "    pyplot.plot(training_loss_array, color=\"orange\")\n",
    "    pyplot.plot(validation_loss_array, color=\"blue\")\n",
    "    pyplot.title(\"Loss vs Epochs\", fontsize=16)\n",
    "    pyplot.ylabel('Loss', fontsize=16)\n",
    "    pyplot.xlabel('Epochs', fontsize=16)\n",
    "    pyplot.legend(['Training Loss', 'Validation Loss'], fontsize=16)\n",
    "\n",
    "    \"\"\" Training and Validation ACCURACY Plot \"\"\"\n",
    "    results_plot.add_subplot(1, 2, 2)\n",
    "    pyplot.plot(training_accuracy_array, color=\"orange\")\n",
    "    pyplot.plot(validation_accuracy_array, color=\"blue\")\n",
    "    pyplot.title(\"Accuracy vs Epochs\", fontsize=16)  # , fontsize=28, pad=20\n",
    "    pyplot.ylabel('Accuracy', fontsize=16)\n",
    "    pyplot.xlabel('Epochs', fontsize=16)\n",
    "    pyplot.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=16)\n",
    "\n",
    "    results_plot.subplots_adjust(top=0.75)\n",
    "    pyplot.tight_layout()\n",
    "    results_folder = \"../results/\"\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "\n",
    "    pyplot.savefig(results_folder + \"model_\" + str(model_no) + \".jpg\")  # , dpi=450)\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_heatmap(model_no, predictions_, labels_tensor_):\n",
    "\n",
    "    predictions_ = predictions_.tolist()\n",
    "    labels_ = labels_tensor_.tolist()\n",
    "\n",
    "    confusion_matrix_ = confusion_matrix(labels_, predictions_)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_, display_labels=classes_folders)\n",
    "    cm_display.plot()\n",
    "    pyplot.title('Model_no = ' + str(model_no) + '   Confusion Matrix of Test Set', x=0.2, fontsize=17)\n",
    "    pyplot.ylabel('Actual Class', fontsize=13)\n",
    "    pyplot.xlabel('Predicted Class', fontsize=13)\n",
    "    pyplot.xticks(rotation=90)\n",
    "    pyplot.tight_layout()\n",
    "\n",
    "    results_folder = \"../results/\"\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "    pyplot.savefig(results_folder + \"model_\" + str(model_no) + \"_confusion.jpg\")\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    # It can be considered as: this block branches out into two, then merges.\n",
    "    # There is a Residual connection from the start of the block, connects to the end of the block.\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # image size: 16 x 28 x 28\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # image size: 32 x 28 x 28\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # image size: 16 x 28 x 28\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Residual connection's value is directly (identity) added to the parallel layers' output.\n",
    "        return self.model(x) + x\n",
    "\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, use_residual, dropout_probability=0.0):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.use_residual, self.dropout_probability = use_residual, dropout_probability\n",
    "\n",
    "        \"\"\" A custom architecture \"\"\"\n",
    "\n",
    "        layers = [\n",
    "            # Convolutional Layers\n",
    "            # image size: 3 x 224 x 224\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # image size: 16 x 112 x 112\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # image size: 16 x 56 x 56\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "            # image size: 16 x 28 x 28\n",
    "        ]\n",
    "\n",
    "        if self.use_residual:\n",
    "            layers.append(ResidualBlock())\n",
    "        else:\n",
    "            layers.extend([\n",
    "                nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "\n",
    "        layers.extend([\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        ])\n",
    "\n",
    "        if self.dropout_probability > 0.1:\n",
    "            \"\"\" Dropout layer randomly (different for each forward pass) sets some of its inputs to zero during training.\n",
    "            This helps regularization and thus reduces the risk of OverFitting, increases generalization ability.\n",
    "\n",
    "            It is generally recommended to dropout towards the end, closer to the fully connected layers,\n",
    "            so that, network will be forced to be more adaptive and rely less heavily on specific features or neurons. \"\"\"\n",
    "            layers.append(nn.Dropout(p=self.dropout_probability))\n",
    "\n",
    "        layers.extend([\n",
    "            # image size: 16 x 28 x 28\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # output size: 16 x 14 x 14 = 3136\n",
    "            nn.Flatten(),\n",
    "            # Fully Connected Layer\n",
    "            nn.Linear(in_features=3136, out_features=8)\n",
    "        ])\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model_no, use_residual, epoch_number, batch_size, learning_rate, dropout_probability=0.0):\n",
    "\n",
    "    model_title = \"model_no=\" + str(model_no) + \" , use_residual=\" + str(use_residual) + \" , epoch=\" + str(epoch_number) + \"\\n\"\n",
    "    model_title += \"batch_size=\" + str(batch_size) + \" , learning_rate=\" + str(learning_rate)\n",
    "    if dropout_probability > 0.1:\n",
    "        model_title += \" , dropout_probability=\" + str(dropout_probability)\n",
    "    print(\"\\n - - - - - - - - - - - - - \\nTraining started for   Model_no =\", model_no,  \"\\n\")\n",
    "\n",
    "    global_start = time.time()\n",
    "\n",
    "    training_loss_array.clear()\n",
    "    training_accuracy_array.clear()\n",
    "    validation_loss_array.clear()\n",
    "    validation_accuracy_array.clear()\n",
    "\n",
    "    model = CustomCNN(use_residual, dropout_probability)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initial Performance\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        training_outputs = model(training_images_tensor)\n",
    "        training_loss = criterion(training_outputs, training_labels_tensor).item()\n",
    "\n",
    "        _, training_predictions = torch.max(training_outputs, 1)\n",
    "        training_accuracy = sum(np.array(training_predictions) == np.array(training_labels_tensor)) / len(training_labels_tensor)\n",
    "\n",
    "        validation_outputs = model(validation_images_tensor)\n",
    "        validation_loss = criterion(validation_outputs, validation_labels_tensor).item()\n",
    "\n",
    "        _, validation_predictions = torch.max(validation_outputs, 1)\n",
    "        validation_accuracy = sum(np.array(validation_predictions) == np.array(validation_labels_tensor)) / len(validation_labels_tensor)\n",
    "\n",
    "        print(\"Before Training (0 Epochs):     \", end=\"\")\n",
    "        print(f'Training Loss: {training_loss:.3f} , Validation Loss: {validation_loss:.3f}', end=\" \")\n",
    "        print(f', Training Accuracy: {training_accuracy:.3f} , Validation Accuracy: {validation_accuracy:.3f}')\n",
    "        # plotting purposes\n",
    "        training_loss_array.append(training_loss)\n",
    "        training_accuracy_array.append(training_accuracy)\n",
    "        validation_loss_array.append(validation_loss)\n",
    "        validation_accuracy_array.append(validation_accuracy)\n",
    "\n",
    "    for epoch in range(epoch_number):\n",
    "        model.train()  # training mode\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        for batch_start in range(0, len(training_images_tensor), batch_size):\n",
    "\n",
    "            batch_images = training_images_tensor[batch_start:batch_start + batch_size]  # batch size x 3 x height x width\n",
    "            batch_labels = training_labels_tensor[batch_start:batch_start + batch_size]\n",
    "\n",
    "            optimizer.zero_grad()  # clear gradients of previous iteration, because pytorch keeps them\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_images)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print(\" a Batch is processed in \", str(int(time.time() - batch_start_time)), \"seconds\")\n",
    "\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        with torch.no_grad():  # disable gradient calculation mode, in order to use less cpu and memory\n",
    "            training_outputs = model(training_images_tensor)\n",
    "            training_loss = criterion(training_outputs, training_labels_tensor).item()\n",
    "            _, training_predictions = torch.max(training_outputs, 1)\n",
    "            training_accuracy = sum(np.array(training_predictions) == np.array(training_labels_tensor)) / len(training_labels_tensor)\n",
    "\n",
    "            validation_outputs = model(validation_images_tensor)\n",
    "            validation_loss = criterion(validation_outputs, validation_labels_tensor).item()\n",
    "\n",
    "            _, validation_predictions = torch.max(validation_outputs, 1)\n",
    "            validation_accuracy = sum(np.array(validation_predictions) == np.array(validation_labels_tensor)) / len(validation_labels_tensor)\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{epoch_number}],', end=\" \")\n",
    "            print(\" took \", str(int(time.time() - epoch_start_time)), \"seconds.  \", end=\"\")\n",
    "            print(f'Training Loss: {training_loss:.3f} , Validation Loss: {validation_loss:.3f}', end=\" \")\n",
    "            print(f', Training Accuracy: {training_accuracy:.3f} , Validation Accuracy: {validation_accuracy:.3f}')\n",
    "            # plotting purposes\n",
    "            training_loss_array.append(training_loss)\n",
    "            training_accuracy_array.append(training_accuracy)\n",
    "            validation_loss_array.append(validation_loss)\n",
    "            validation_accuracy_array.append(validation_accuracy)\n",
    "\n",
    "    test_outputs = model(test_images_tensor)\n",
    "    test_loss = criterion(validation_outputs, test_labels_tensor).item()\n",
    "    _, test_predictions = torch.max(test_outputs, 1)\n",
    "    test_accuracy = sum(np.array(test_predictions) == np.array(test_labels_tensor)) / len(test_labels_tensor)\n",
    "    print(f'\\nAFTER TRAINING:  model_no={model_no},  TEST SET RESULTS: , Test Loss: {test_loss:.2f}, Test ACCURACY:  {(test_accuracy*100):.2f}%\\n')\n",
    "\n",
    "    draw_results_plots(model_no, model_title)\n",
    "    plot_confusion_matrix_heatmap(model_no, test_predictions, test_labels_tensor)\n",
    "\n",
    "    print(\"* *  Execution completed. Total time:  \", int(time.time() - global_start), \" seconds.  * * \\n\")\n",
    "    # never tried: Save the trained model: torch.save(model.state_dict(), 'custom_cnn_model.pth')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Choose and Train a model.\n",
    "## Models differ by Hyper-Parameters and some Architectural differences.\n",
    "<br>\n",
    "\n",
    "A model train and evaluation take around 700 seconds for 80 Epochs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Models without Residual Connection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=1, use_residual=False, epoch_number=80, batch_size=20, learning_rate=0.0001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=2, use_residual=False, epoch_number=80, batch_size=20, learning_rate=0.0003)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=3, use_residual=False, epoch_number=80, batch_size=40, learning_rate=0.0001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=4, use_residual=False, epoch_number=80, batch_size=40, learning_rate=0.0003)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Models with Residual Connection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=5, use_residual=True, epoch_number=80, batch_size=20, learning_rate=0.0001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=6, use_residual=True, epoch_number=80, batch_size=20, learning_rate=0.0003)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=7, use_residual=True, epoch_number=80, batch_size=40, learning_rate=0.0001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=8, use_residual=True, epoch_number=80, batch_size=40, learning_rate=0.0003)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DROPOUT\n",
    "\n",
    "### The best model among those Without Residual Connection is model_4,\n",
    "### and the best model among those With Residual Connection is model_8.\n",
    "\n",
    "### Now, let's try different Dropout Probability values on these best models. And obtain model_9, 10, 11, 12."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=9, use_residual=False, epoch_number=80, batch_size=40, learning_rate=0.0003, dropout_probability=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=10, use_residual=False, epoch_number=80, batch_size=40, learning_rate=0.0003, dropout_probability=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=11, use_residual=True, epoch_number=80, batch_size=40, learning_rate=0.0003, dropout_probability=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_and_evaluate_model(model_no=12, use_residual=True, epoch_number=80, batch_size=40, learning_rate=0.0003, dropout_probability=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### End of Part 1."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
