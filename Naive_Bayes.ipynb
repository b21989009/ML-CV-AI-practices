{"cells":[{"cell_type":"markdown","source":["## BBM409 Introduction to Machine Learning Lab.  Fall 2022.\n","# Assignment 3"],"metadata":{"collapsed":false,"id":"biTt3w-QifuN"}},{"cell_type":"markdown","source":["### Contributors:\n","\n","### Ali Argun Sayilgan   : 21827775\n","### Mehmet Giray Nacakci :  21989009"],"metadata":{"collapsed":false,"id":"GUv3ytxCifuU"}},{"cell_type":"markdown","source":["## Please run this report with   \"RUN ALL\" command\n","\n","### It takes around 40 seconds to get all the results."],"metadata":{"collapsed":false,"id":"mcImtk6nifuU"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n","from sklearn.model_selection import train_test_split\n","from collections import Counter, OrderedDict\n","from operator import itemgetter\n","import pandas as pd\n","pd.set_option('display.precision', 2)\n","import numpy as np\n","import math\n","import time"],"metadata":{"id":"2tRO2zLTifuV"}},{"cell_type":"markdown","source":["## Classification of News Articles\n","\n","The Dataset consists of 1490 English News Articles, each belonging to one of the 5 categories (Sport, Business, Politics, Entertainment, Tech).\n","We implemented the Naive Bayes Classifier Algorithm to predict categories of Articles."],"metadata":{"collapsed":false,"id":"4JyxzhG3ifuW"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jRxpBVxyifuX","outputId":"cb912e61-03ce-45c1-b037-da3bc0462042"},"outputs":[{"data":{"text/plain":"   ArticleId                                               Text       Category\n0       1833  worldcom ex-boss launches defence lawyers defe...       business\n1        154  german business confidence slides german busin...       business\n2       1101  bbc poll indicates economic gloom citizens in ...       business\n3       1976  lifestyle  governs mobile choice  faster  bett...           tech\n4        917  enron bosses in $168m payout eighteen former e...       business\n5       1582  howard  truanted to play snooker  conservative...       politics\n6        651  wales silent on grand slam talk rhys williams ...          sport\n7       1797  french honour for director parker british film...  entertainment","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArticleId</th>\n      <th>Text</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1833</td>\n      <td>worldcom ex-boss launches defence lawyers defe...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>154</td>\n      <td>german business confidence slides german busin...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1101</td>\n      <td>bbc poll indicates economic gloom citizens in ...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1976</td>\n      <td>lifestyle  governs mobile choice  faster  bett...</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>917</td>\n      <td>enron bosses in $168m payout eighteen former e...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1582</td>\n      <td>howard  truanted to play snooker  conservative...</td>\n      <td>politics</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>651</td>\n      <td>wales silent on grand slam talk rhys williams ...</td>\n      <td>sport</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1797</td>\n      <td>french honour for director parker british film...</td>\n      <td>entertainment</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"sport            346\nbusiness         336\npolitics         274\nentertainment    273\ntech             261\nName: Category, dtype: int64"},"metadata":{},"output_type":"display_data"}],"source":["df = pd.read_csv(\"English Dataset.csv\")\n","accuracies = []\n","\n","display(df.head(8))\n","display(df.Category.value_counts())"]},{"cell_type":"markdown","source":["Dataset is balanced, all categories have similar amount of samples. This is expected to cause less/no bias in ml models' predictions."],"metadata":{"collapsed":false,"id":"oL04iL5ZifuY"}},{"cell_type":"markdown","source":["# PART 1: Understanding the data\n","\n","Using Count Vectorizer, displaying most commonly occurring words for each category,\n","and guessing what words could be an important factor in classification for each category.\n","\n","In this part, we temporarily cleaned-up the dataset from stop words to see actual categorically significant words."],"metadata":{"collapsed":false,"id":"qHsFQyQ-ifuZ"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Most common 25 words in  SPORT  category are: \n","       ['said : 636', 'game : 356', 'year : 331', 'england : 329', 'time : 296', 'win : 295', 'world : 269', 'players : 209', 'cup : 206', 'team : 205', 'new : 202', 'ireland : 194', 'half : 194', 'play : 193', 'just : 192', 'second : 189', 'wales : 183', 'match : 180', 'final : 180', 'won : 175', 'good : 170', 'season : 166', 'set : 161', 'france : 158', 'chelsea : 157', 'coach : 150']\n","\n","Most common 25 words in  BUSINESS  category are: \n","       ['said : 1100', 'year : 456', 'mr : 393', 'market : 284', 'new : 273', 'firm : 261', 'growth : 257', 'company : 253', 'economy : 233', 'government : 215', 'bank : 206', 'economic : 202', 'sales : 201', '2004 : 199', 'oil : 179', '000 : 175', 'shares : 171', 'world : 169', 'years : 162', 'chief : 156', 'business : 155', 'deal : 152', 'uk : 149', 'china : 140', 'financial : 140', 'companies : 140']\n","\n","Most common 25 words in  POLITICS  category are: \n","       ['said : 1445', 'mr : 1073', 'labour : 494', 'government : 464', 'election : 424', 'blair : 395', 'party : 376', 'people : 372', 'minister : 286', 'new : 280', 'brown : 264', 'uk : 254', 'told : 219', 'plans : 212', 'public : 204', 'howard : 197', 'prime : 194', 'say : 186', 'tax : 184', 'britain : 181', 'secretary : 178', 'year : 175', 'tory : 170', 'general : 166', 'leader : 164', 'says : 159']\n","\n","Most common 25 words in  ENTERTAINMENT  category are: \n","       ['said : 594', 'film : 583', 'best : 430', 'year : 315', 'music : 255', 'new : 234', 'awards : 184', 'uk : 171', 'actor : 169', 'number : 165', 'won : 164', 'band : 162', 'star : 160', 'director : 159', 'award : 152', 'mr : 151', 'tv : 142', 'films : 138', 'time : 136', 'years : 135', 'british : 133', 'people : 127', 'bbc : 125', 'album : 125', 'including : 116', 'actress : 116']\n","\n","Most common 25 words in  TECH  category are: \n","       ['said : 1064', 'people : 647', 'new : 349', 'mr : 349', 'mobile : 343', 'technology : 303', 'users : 268', 'software : 265', 'use : 260', 'net : 256', 'music : 255', 'year : 251', 'digital : 244', 'games : 227', 'phone : 227', 'make : 217', 'like : 216', 'service : 202', 'computer : 196', 'microsoft : 196', 'time : 196', 'uk : 196', 'online : 191', 'used : 189', 'just : 186', 'world : 183']\n","\n"]}],"source":["categories = [\"sport\", \"business\", \"politics\", \"entertainment\", \"tech\"]\n","for category in categories:\n","    subset = df[df['Category'] == category]\n","\n","    vectorizer = CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n","\n","    word_counts_for_each_sample = vectorizer.fit_transform(subset[\"Text\"].to_numpy())\n","    word_counts_in_total = np.sum(word_counts_for_each_sample, axis=0).tolist()\n","\n","    words_list = vectorizer.get_feature_names_out()\n","    most_frequent_words_indices = np.flip(np.argsort(word_counts_in_total)[0])\n","    most_frequent_words = []\n","    count_ = 0\n","\n","    for i in most_frequent_words_indices:\n","\n","        this_word = words_list[i]\n","        most_frequent_words.append(this_word + \" : \" + str(word_counts_in_total[0][i]))\n","        count_ += 1\n","\n","        if count_ > 25:\n","            break\n","\n","    print(\"Most common 25 words in  \" + category.upper() + \"  category are: \\n       \" + str(most_frequent_words) + \"\\n\")\n"],"metadata":{"id":"4hUVm3_BifuZ","outputId":"e6d2273e-e3d1-4eb8-a7c0-29e5d473ebc0"}},{"cell_type":"markdown","source":["From the results, for each category, the most relevant (frequent) words (likely have a role in classification) we think are:\n","\n","SPORT:  game, players, cup, team, season, match, play\n","BUSINESS: market, growth, company, business, financial, companies, economic\n","POLITICS: labour, government, election, party, leader, minister\n","ENTERTAINMENT: film, music, awards, actor, director, album\n","TECH: mobile, technology, software, digital, computer, online\n","\n","This list is based on the dataset and result is intuitive since these words are the natural vocabulary of the five specific topics.\n","Therefore, using Naive Bayes Algorithm will be feasible to classify articles based on frequently occurring words.\n","\n","In next chapters we will examine if these really are the words that guide the classification."],"metadata":{"collapsed":false,"id":"UNme26SKifua"}},{"cell_type":"markdown","source":["# PART 2: Implementing Naive Bayes"],"metadata":{"collapsed":false,"id":"fgxuxm2_ifub"}},{"cell_type":"markdown","source":["#### Data Clean-up\n","\n","Dataset consists of unrelated numerical strings and clutter such as '000', '05', '10', 'a100', '100m', '10m'.\n","These terms should be completely removed from the dataset, as they do not make sense for category-related classification."],"metadata":{"collapsed":false,"id":"7RtBDaN6ifub"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def data_cleanup(dataset_x):\n","    # Remove terms that are not mostly consisting of alphabetical characters\n","    for r in range(len(dataset_x)):\n","        document_ = dataset_x[r]\n","        row_words = document_.split()\n","        filtered_document = []\n","        for a_word in row_words:\n","            letter_character_count = sum(char_.isalpha() for char_ in a_word)\n","\n","            if letter_character_count > len(a_word)//2:\n","                filtered_document.append(a_word)\n","\n","        dataset_x[r] = \" \".join(filtered_document)\n","    return dataset_x"],"metadata":{"id":"pOpnE-pIifub"}},{"cell_type":"markdown","source":["#### Dataset Split\n","##### (80% Train, 20% Test)"],"metadata":{"collapsed":false,"id":"mqyVkSsaifuc"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["# 1490 samples\n","X = df.Text\n","Y = df.Category\n","\n","X = X.to_numpy()\n","X = data_cleanup(X)\n","Y = Y.to_numpy()\n","\n","# shuffle the dataset, then split as 80% Train and 20% Test.\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=24, shuffle=True, stratify=Y)\n","# stratify: keeps the proportion of classes (compared to each other) stable, while splitting the dataset.\n"],"metadata":{"id":"sgi_1iQ4ifuc"}},{"cell_type":"markdown","source":["### TRAINING  (Creating Vocabularies from Training Articles)\n","\n","Text vectorization: Articles are turned into n-feature vectors. n is the articles' split to terms.\n","\n","Bag of Words (BoW) model learns occurrences (counts, frequencies) of each term in documents, then total for each category.\n","<br/>\n","\n","#### \"Term\" can be:\n","   * #### Unigram: individual Word\n","   * #### Bigram:  two adjacent words\n","\n","Terms are then mapped (dictionary creation) to their frequencies, creating Vocabularies for each category."],"metadata":{"collapsed":false,"id":"7woLMsGgifuc"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["category_frequencies = pd.Series(y_train).value_counts().to_dict()\n","categories = list(category_frequencies.keys())\n","\n","\"\"\" UNIGRAM : Creating UNIGRAM Dictionaries: The frequencies of individual words in documents. \"\"\"\n","\n","dictionaries_unigram = []\n","for category in categories:\n","\n","    subset = X_train[np.where(y_train == category)]\n","    vectorizer = CountVectorizer()\n","    word_counts_for_each_sample = vectorizer.fit_transform(subset)\n","    word_counts_in_total = np.sum(word_counts_for_each_sample, axis=0).tolist()\n","    words_list = vectorizer.get_feature_names_out()\n","\n","    word_to_count_dictionary = {}\n","    for n in range(len(words_list)):\n","        word_to_count_dictionary[words_list[n]] = word_counts_in_total[0][n]\n","\n","    dictionaries_unigram.append(word_to_count_dictionary)\n","\n","\n","\"\"\" BIGRAM: Creating BIGRAM Dictionaries: The frequencies of two adjacent words in documents. \"\"\"\n","\n","dictionaries_bigram = []\n","for category in categories:\n","\n","    subset = X_train[np.where(y_train == category)]\n","    vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n","    bigram_counts_for_each_sample = vectorizer.fit_transform(subset)\n","    bigram_counts_in_total = np.sum(bigram_counts_for_each_sample, axis=0).tolist()\n","    bigrams_list = vectorizer.get_feature_names_out()\n","\n","    bigram_to_count_dictionary = {}\n","    for n in range(len(bigrams_list)):\n","        bigram_to_count_dictionary[bigrams_list[n]] = bigram_counts_in_total[0][n]\n","\n","    dictionaries_bigram.append(bigram_to_count_dictionary)\n"],"metadata":{"id":"nxDygfRjifud"}},{"cell_type":"markdown","source":["## Naive Bayes Classification"],"metadata":{"collapsed":false,"id":"6S52R7nNifud"}},{"cell_type":"markdown","source":["General formula of Naive Bayes Classifier:\n","<br/>\n","\n","<img src=\"data:image/png;base64,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\" width=\"400\">\n","<br/>\n","\n","where vj is the set of 5 Categories (labels), and ai are other attributes (each term in vocabulary)\n","<br/>\n","To Classify a test sample to a one of the 5 categories, we will compare conditional probability chains that lead to those 5 categories for this sample.\n","The bigger probability one wins. The individual probability terms in calculations (ratios of existence) are inferred from Vocabularies created in Training.\n","<br/>\n","\n","    Suppose we have a Test sample.  Article = \"This musician created an album after the election yeah election music election ... \"\n","\n","General formula for probability of a sample belonging to a class(category):\n","\n","    P(this test sample is entertainment) = p(entertainment) *  for each feature: { p(probability of this feature | entertainment) }\n","\n","For term (word or bigram) frequency:\n","\n","    P(this test sample is entertainment) = p(entertainment) *  for each [unique or not] term: { p(probability of this term | in entertainment) }\n","\n","For preventing Floating Point Underflow:\n","\n","    P(this test sample is entertainment) = log[p(entertainment)] +  for each [unique or not] term: { log [ p(probability of this term | in entertainment) ] }\n","\n","We will be using the third, sum of LOGs formula in our calculations.\n","\n","\n","<br/>\n","\n","### Two alternatives are implemented and compared:\n","\n","* ### NON-UNIQUE:\n","#### Looping over (calculating and summing up) Probability for EACH Term in a Test sample one-by-one.\n","##### This way, a Term appears more frequently in the Test sample has more affect than another one that appears once.\n","<br/>\n","\n","* ### UNIQUE:\n","#### Looping over not EACH but Each UNIQUE Terms in a Test sample.\n"],"metadata":{"collapsed":false,"id":"2hrBxlqjifue"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def find_probability_of_word_or_bigram_in_category(category_index_, word_or_bigram, vocabulary):\n","\n","    frequency_ = 0\n","\n","    if word_or_bigram in vocabulary.keys():\n","        frequency_ = vocabulary.get(word_or_bigram)\n","\n","    # Laplace Smoothing:  prevent zero probability\n","    return (frequency_ + 1) / (category_frequencies.get(categories[category_index_]) + 5)  # 5 is for 5 categories\n","\n","\n","def accuracy(predictions_, ground_truths_):\n","    return sum(np.array(predictions_) == np.array(ground_truths_)) / len(predictions_)\n","\n","\n","def classify_test_set_samples(is_bigram, is_for_unique, vocabulary_dictionaries):\n","\n","    predictions = []\n","    actual_categories = []\n","    start = time.time()\n","\n","    for p, this_sample in enumerate(X_test):\n","\n","        probabilities_of_this_sample_for_each_category = []  # best one wins classification\n","        for c, category_ in enumerate(categories):\n","\n","            # initially, prior probability  P(this category's probability itself)\n","            prob_of_being_this_category = category_frequencies.get(category_) / len(y_train)\n","\n","\n","            \"\"\" posterior probabilities \"\"\"\n","\n","            words_ = this_sample.split()\n","            terms_ = words_\n","\n","            if is_bigram:\n","                bigrams_ = [words_[q] + \" \" + words_[q+1] for q in range(len(words_) - 1)]\n","                terms_ = bigrams_\n","\n","            if is_for_unique:\n","                terms_ = np.unique(terms_)\n","                \"\"\"\n","                NON-UNIQUE: Looping over (calculating and summing up) Probability for EACH Term in Test sample one-by-one.\n","                    This way, a Term appears more frequently has more affect than another one that appears once.\n","                UNIQUE: Looping over not EACH but Each UNIQUE Terms in Test sample.\n","                \"\"\"\n","\n","            for term_ in terms_:\n","                prob_of_being_this_category += math.log(find_probability_of_word_or_bigram_in_category(c, term_, vocabulary_dictionaries[c]))\n","\n","            probabilities_of_this_sample_for_each_category.append(prob_of_being_this_category)\n","\n","        predicted_category_of_this_sample = categories[np.argmax(probabilities_of_this_sample_for_each_category)]\n","        predictions.append(predicted_category_of_this_sample)\n","        actual_categories.append(y_test[p])\n","\n","\n","    print(str(len(X_test))  + \"  samples predicted  in  \", end=\" \")\n","    print('%d  seconds \\n' %(time.time()-start))\n","    print(\"Predicted:  \" + str(OrderedDict(sorted(Counter(predictions).items()))))\n","    print(\"Actual:  :  \" + str(OrderedDict(sorted(Counter(actual_categories).items()))))\n","    accuracy_ = accuracy(predictions, actual_categories)\n","    print(\"\\n ACCURACY:  \" + str(round(accuracy_, 3)) + \"\\n\")\n","    return accuracy_\n","\n","\n","def classify_all(unigram_vocabulary, bigram_vocabulary):\n","    \"\"\" Classify Test set with All model variations, using inputted Vocabularies \"\"\"\n","\n","    print(\"UNIGRAM   --------- --   UNIGRAM   ------- ----   UNIGRAM   ------------   UNIGRAM   ------------   UNIGRAM   -----\\n\")\n","    print(\"- - - -  UNIGRAMS.  NON-UNIQUE Test Terms  - - - -\\n\")\n","    accuracies.append(classify_test_set_samples(False, False, unigram_vocabulary))\n","    print(\"- - - -  UNIGRAMS.  UNIQUE Test Terms  - - - -\\n\")\n","    accuracies.append(classify_test_set_samples(False, True, unigram_vocabulary))\n","\n","    print(\"\\nBIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   ----\\n\")\n","    print(\"- - - -  BIGRAMS.  NON-UNIQUE Test Terms  - - - -\\n\")\n","    accuracies.append(classify_test_set_samples(True, False, bigram_vocabulary))\n","    print(\"- - - -  BIGRAMS.  UNIQUE Test Terms - - - -\\n\")\n","    accuracies.append(classify_test_set_samples(True, True, bigram_vocabulary))\n"],"metadata":{"id":"wyaKZ4ddifuf"}},{"cell_type":"markdown","source":["#### UNIGRAM & BIGRAM Classification Results"],"metadata":{"collapsed":false,"id":"lyHLrswTifug"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["UNIGRAM   --------- --   UNIGRAM   ------- ----   UNIGRAM   ------------   UNIGRAM   ------------   UNIGRAM   -----\n","\n","- - - -  UNIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 41), ('entertainment', 31), ('politics', 70), ('sport', 63), ('tech', 93)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.809\n","\n","- - - -  UNIGRAMS.  UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 45), ('entertainment', 32), ('politics', 69), ('sport', 66), ('tech', 86)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.836\n","\n","\n","BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   ----\n","\n","- - - -  BIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 31), ('entertainment', 40), ('politics', 77), ('sport', 42), ('tech', 108)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.728\n","\n","- - - -  BIGRAMS.  UNIQUE Test Terms - - - -\n","\n","298  samples predicted  in   1  seconds \n","\n","Predicted:  OrderedDict([('business', 25), ('entertainment', 39), ('politics', 76), ('sport', 42), ('tech', 116)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.708\n","\n"]}],"source":["classify_all(dictionaries_unigram, dictionaries_bigram)"],"metadata":{"id":"nuolb5isifuh","outputId":"25503efe-2336-45e7-c121-291feb86b853"}},{"cell_type":"markdown","source":["We were actually expecting Bigrams to perform better than Unigrams, since a category specific word couple such as \"music industry\" could be more related to Entertainment category than just \"music\" or \"industry\". Yet, Unigrams seem to perform about 10% better than Bigrams.\n","\n","It seems that all vocabulary variations seem to favor predicting Tech and Politics more than other categories."],"metadata":{"collapsed":false,"id":"z-TSGQroifuh"}},{"cell_type":"markdown","source":["# PART 3"],"metadata":{"collapsed":false,"id":"ceT7qITjifui"}},{"cell_type":"markdown","source":["# PART 3 : A\n","## First Objective: Analyzing the strongest and weakest Terms\n","## in terms of their effect on prediction\n","\n","Considering Naive Bayes classification:\n","\n","    P(this test sample is entertainment) = p(entertainment) *  for each [unique or not] term: { p(probability of this term | in entertainment) }\n","\n","This posterior probability is determined from previous events (training data). Since a Training Dictionary Term has as much effect as it's occurrence (frequency), we will directly analyse TF-IDF (Term Frequency - Inverse Document Frequency)(or Relevance) measure for each word in training vocabulary.\n","\n","Then, we will display the most and least effective/significant words of each article category.\n"],"metadata":{"collapsed":false,"id":"nKPqdydRifui"}},{"cell_type":"markdown","source":["#### Term Frequency:\n","Occurrence ratio of this term (word or bigram) in this Category (article, sample). Similar to our find_probability_of_word_or_bigram_in_category( ) function.\n","    = log ( 1  +  this term's occurrence in this category / total terms in this category )\n","<br/>\n","\n","#### Inverse Document Frequency:\n","is a measure related to \"How many categories contain this term?, How special is it?\". If this term appears in many categories, it is probably not that category-specific and cannot help much in classification.  For example, IDF = 0  if this term is contained in all documents.\n","    = log (all categories / categories that contain this term)\n","<br/>\n","\n","#### And TD-IDF\n","is calculated as the product of the two:   TF * IDF.\n","High score means this word is relevant to this category. How important is this word for this category, in the context of the whole collection?\n","\n"],"metadata":{"collapsed":false,"id":"3uvA8DXnifui"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Category:  SPORT\n","  10 Most effective Words: \n","    dict_keys(['roddick', 'chelsea', 'coach', 'nadal', 'referee', 'athens', 'arsenal', 'tennis', 'championships', 'slam'])\n","  10 Least effective Words: \n","    dict_keys(['10', '30', 'ability', 'able', 'about', 'above', 'absolute', 'absolutely', 'accept', 'acceptable'])\n","\n","Category:  BUSINESS\n","  10 Most effective Words: \n","    dict_keys(['yukos', 'economy', 'lse', 'imf', 'deficit', 'gm', 'worldcom', 'ebbers', 'market', 'boerse'])\n","  10 Least effective Words: \n","    dict_keys(['10', '30', 'ability', 'able', 'about', 'above', 'absolute', 'absolutely', 'accept', 'acceptable'])\n","\n","Category:  POLITICS\n","  10 Most effective Words: \n","    dict_keys(['tory', 'tories', 'kilroy', 'ukip', 'lib', 'lords', 'chancellor', 'asylum', 'labour', 'mps'])\n","  10 Least effective Words: \n","    dict_keys(['10', '30', 'ability', 'able', 'about', 'above', 'absolute', 'absolutely', 'accept', 'acceptable'])\n","\n","Category:  ENTERTAINMENT\n","  10 Most effective Words: \n","    dict_keys(['album', 'actress', 'festival', 'film', 'oscar', 'chart', 'aviator', 'awards', 'movie', 'comedy'])\n","  10 Least effective Words: \n","    dict_keys(['10', '30', 'ability', 'able', 'about', 'above', 'absolute', 'absolutely', 'accept', 'acceptable'])\n","\n","Category:  TECH\n","  10 Most effective Words: \n","    dict_keys(['software', 'users', 'spam', 'microsoft', 'gadgets', 'mobiles', 'portable', 'bt', 'digital', 'consumers'])\n","  10 Least effective Words: \n","    dict_keys(['10', '30', 'ability', 'able', 'about', 'above', 'absolute', 'absolutely', 'accept', 'acceptable'])\n","\n","Category:  SPORT\n","  10 Most effective BIGRAMs: \n","    dict_keys(['the match', 'six nations', 'grand slam', 'australian open', 'davis cup', 'the ball', 'champions league', 'his side', 'olympic champion', 'the iaaf'])\n","  10 Least effective BIGRAMs: \n","    dict_keys(['ability to', 'able to', 'about it', 'about the', 'about this', 'about to', 'about what', 'according to', 'accused of', 'across the'])\n","\n","Category:  BUSINESS\n","  10 Most effective BIGRAMs: \n","    dict_keys(['stock market', 'mr glazer', 'analysts said', 'deutsche boerse', 'oil prices', 'the economy', 'mr ebbers', 'the dollar', 'the lse', 'consumer spending'])\n","  10 Least effective BIGRAMs: \n","    dict_keys(['ability to', 'able to', 'about it', 'about the', 'about this', 'about to', 'about what', 'according to', 'accused of', 'across the'])\n","\n","Category:  POLITICS\n","  10 Most effective BIGRAMs: \n","    dict_keys(['the party', 'the tories', 'kilroy silk', 'michael howard', 'the chancellor', 'mr blair', 'the conservatives', 'liberal democrats', 'home secretary', 'the liberal'])\n","  10 Least effective BIGRAMs: \n","    dict_keys(['ability to', 'able to', 'about it', 'about the', 'about this', 'about to', 'about what', 'according to', 'accused of', 'across the'])\n","\n","Category:  ENTERTAINMENT\n","  10 Most effective BIGRAMs: \n","    dict_keys(['the band', 'the film', 'the aviator', 'for best', 'vera drake', 'best actress', 'nominated for', 'named best', 'the ceremony', 'the festival'])\n","  10 Least effective BIGRAMs: \n","    dict_keys(['ability to', 'able to', 'about it', 'about the', 'about this', 'about to', 'about what', 'according to', 'accused of', 'across the'])\n","\n","Category:  TECH\n","  10 Most effective BIGRAMs: \n","    dict_keys(['high definition', 'wi fi', 'mac mini', 'consumer electronics', 'file sharing', 'the mac', 'the software', 'the web', 'digital cameras', 'peer to'])\n","  10 Least effective BIGRAMs: \n","    dict_keys(['ability to', 'able to', 'about it', 'about the', 'about this', 'about to', 'about what', 'according to', 'accused of', 'across the'])\n"]}],"source":["\n","\"\"\" UNIGRAM \"\"\"\n","\n","tfidf_for_unigrams_in_categories = []\n","\n","for m, dictionary_ in enumerate(dictionaries_unigram):\n","\n","    this_category_words_to_tfidf_s = {}\n","\n","    for word_ in dictionary_.keys():\n","        term_frequency = dictionary_.get(word_) / category_frequencies.get(categories[m])\n","\n","        how_many_categories_contain_this_term = 0\n","        for a_category_dictionary_ in dictionaries_unigram:\n","            if word_ in a_category_dictionary_.keys():\n","                how_many_categories_contain_this_term += 1\n","        inverse_document_frequency = math.log(5 / how_many_categories_contain_this_term)\n","\n","        tf_idf = term_frequency * inverse_document_frequency\n","        this_category_words_to_tfidf_s[word_] = tf_idf\n","\n","    tfidf_for_unigrams_in_categories.append(this_category_words_to_tfidf_s)\n","\n","\n","    print(\"\\nCategory:  \" + categories[m].upper())\n","\n","    # highest TF-IDF values\n","    most_effective_10_words = dict(sorted(this_category_words_to_tfidf_s.items(), key = itemgetter(1), reverse = True)[:10]).keys()\n","    print(\"  10 Most effective Words: \\n    \" + str(most_effective_10_words))\n","\n","    # lowest TF-IDF values\n","    least_effective_10_words = dict(sorted(this_category_words_to_tfidf_s.items(), key = itemgetter(1))[:10]).keys()\n","    print(\"  10 Least effective Words: \\n    \" + str(least_effective_10_words))\n","\n","\n","\n","\"\"\" BIGRAM \"\"\"\n","\n","tfidf_for_bigrams_in_categories = []\n","\n","for m, dictionary_ in enumerate(dictionaries_bigram):\n","\n","    this_category_bigrams_to_tfidf_s = {}\n","\n","    for bigram_ in dictionary_.keys():\n","        term_frequency = dictionary_.get(bigram_) / category_frequencies.get(categories[m])\n","\n","        how_many_categories_contain_this_term = 0\n","        for a_category_dictionary_ in dictionaries_bigram:\n","            if bigram_ in a_category_dictionary_.keys():\n","                how_many_categories_contain_this_term += 1\n","        inverse_document_frequency = math.log(5 / how_many_categories_contain_this_term)\n","\n","        tf_idf = term_frequency * inverse_document_frequency\n","        this_category_bigrams_to_tfidf_s[bigram_] = tf_idf\n","\n","    tfidf_for_bigrams_in_categories.append(this_category_bigrams_to_tfidf_s)\n","\n","\n","    print(\"\\nCategory:  \" + categories[m].upper())\n","\n","    # highest TF-IDF values\n","    most_effective_10_bigrams = dict(sorted(this_category_bigrams_to_tfidf_s.items(), key = itemgetter(1), reverse = True)[:10]).keys()\n","    print(\"  10 Most effective BIGRAMs: \\n    \" + str(most_effective_10_bigrams))\n","\n","    # lowest TF-IDF values\n","    least_effective_10_bigrams = dict(sorted(this_category_bigrams_to_tfidf_s.items(), key = itemgetter(1))[:10]).keys()\n","    print(\"  10 Least effective BIGRAMs: \\n    \" + str(least_effective_10_bigrams))\n"],"metadata":{"id":"0pVbbkaqifui","outputId":"60e92abf-6af2-4ce3-b13c-f4e7e21eb679"}},{"cell_type":"markdown","source":["As observed, most effective terms are closely/uniquely related to the topics of these categories, whereas least effective terms (most of them are stop words) are mostly common between categories, and can be related to anything.\n","\n","We can observe common terms between this part and our most frequent (or relevant in prediction) words guesses from Part 1.\n","Such as:  \"chelsea\", \"coach\", \"the match\" in Sport category;\n","'the software', 'digital cameras', 'mobiles' in Tech category,\n","'album', 'the film', 'awards' in Entertainment category, and so on.\n","\n","Yet, since the most effective words are not necessarily the most frequent words, common terms are not many.\n","That is why frequency is not directly equal to relevance. Uniqueness of a word in a category should be rewarded.\n"],"metadata":{"collapsed":false,"id":"0EAcfsjIifuj"}},{"cell_type":"markdown","source":[],"metadata":{"collapsed":false,"id":"TM2zME6Gifuj"}},{"cell_type":"markdown","source":["# PART 3 : A\n","# Second Objective: Narrowing Down Dictionaries (Eliminating non-effective vocabulary)\n","\n","##### Let us narrow down our vocabularies to  only the most effective portion of the vocabulary, and see if classification results improve.\n","The most effective portion is the portion consisting of highest TD-IDF Terms (calculated in previous section)."],"metadata":{"collapsed":false,"id":"7rISR5MPifuj"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["\n","def narrow_down_dictionaries(narrowing_percentage):\n","\n","    \"\"\" UNIGRAM \"\"\"\n","    narrowed_unigram_dictionaries = []\n","\n","    for category_index, category_tfidf_s in enumerate(tfidf_for_unigrams_in_categories):\n","        len_remaining = math.floor(len(category_tfidf_s) * ((100-narrowing_percentage)/100))\n","        most_effective_part = dict(sorted(category_tfidf_s.items(), key = itemgetter(1), reverse = True)[:len_remaining])\n","\n","        word_to_count_dictionary_ = {}\n","        for word in most_effective_part.keys():\n","            word_to_count_dictionary_[word] = dictionaries_unigram[category_index].get(word)\n","        narrowed_unigram_dictionaries.append(word_to_count_dictionary_)\n","\n","\n","    \"\"\" BIGRAM \"\"\"\n","    narrowed_bigram_dictionaries = []\n","\n","    for category_index, category_tfidf_s in enumerate(tfidf_for_bigrams_in_categories):\n","        len_remaining = math.floor(len(category_tfidf_s) * ((100-narrowing_percentage)/100))\n","        most_effective_part = dict(sorted(category_tfidf_s.items(), key = itemgetter(1), reverse = True)[:len_remaining])\n","\n","        bigram_to_count_dictionary_ = {}\n","        for bigram__ in most_effective_part.keys():\n","            bigram_to_count_dictionary_[bigram__] = dictionaries_bigram[category_index].get(bigram__)\n","        narrowed_bigram_dictionaries.append(bigram_to_count_dictionary_)\n","\n","    return narrowed_unigram_dictionaries, narrowed_bigram_dictionaries"],"metadata":{"id":"YaEka548ifuj"}},{"cell_type":"markdown","source":["#### Classification with 20% Narrowed-Down Dictionaries"],"metadata":{"collapsed":false,"id":"GTwhrn9gifuk"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["UNIGRAM   --------- --   UNIGRAM   ------- ----   UNIGRAM   ------------   UNIGRAM   ------------   UNIGRAM   -----\n","\n","- - - -  UNIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 29), ('entertainment', 46), ('politics', 120), ('sport', 50), ('tech', 53)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.762\n","\n","- - - -  UNIGRAMS.  UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 36), ('entertainment', 43), ('politics', 109), ('sport', 58), ('tech', 52)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.809\n","\n","\n","BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   ----\n","\n","- - - -  BIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 26), ('entertainment', 44), ('politics', 72), ('sport', 34), ('tech', 122)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.698\n","\n","- - - -  BIGRAMS.  UNIQUE Test Terms - - - -\n","\n","298  samples predicted  in   1  seconds \n","\n","Predicted:  OrderedDict([('business', 23), ('entertainment', 44), ('politics', 69), ('sport', 31), ('tech', 131)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.681\n","\n"]}],"source":["classify_all(*narrow_down_dictionaries(20))"],"metadata":{"id":"UGokWdATifuk","outputId":"5c3681bf-dd2d-4df1-9a5e-8d11539c4ecb"}},{"cell_type":"markdown","source":["As it is observed, narrowing-down by 20% is too much. Accuracies of all models are dropped by around 2.5%. We actually desire an increase in accuracy.\n","\n","Apparently, we removed too many actually useful terms. Insignificant terms were not covering such a big portion of the vocabularies.\n","\n","Let us try only 5%."],"metadata":{"collapsed":false,"id":"tPduplTqifuk"}},{"cell_type":"markdown","source":["#### Classification with 5% Narrowed-Down Dictionaries"],"metadata":{"collapsed":false,"id":"hq7mC8wyifuk"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["UNIGRAM   --------- --   UNIGRAM   ------- ----   UNIGRAM   ------------   UNIGRAM   ------------   UNIGRAM   -----\n","\n","- - - -  UNIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 44), ('entertainment', 33), ('politics', 74), ('sport', 63), ('tech', 84)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.829\n","\n","- - - -  UNIGRAMS.  UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 47), ('entertainment', 34), ('politics', 77), ('sport', 64), ('tech', 76)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.842\n","\n","\n","BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   ----\n","\n","- - - -  BIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 25), ('entertainment', 44), ('politics', 74), ('sport', 37), ('tech', 118)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.705\n","\n","- - - -  BIGRAMS.  UNIQUE Test Terms - - - -\n","\n","298  samples predicted  in   1  seconds \n","\n","Predicted:  OrderedDict([('business', 22), ('entertainment', 46), ('politics', 70), ('sport', 33), ('tech', 127)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.691\n","\n"]}],"source":["classify_all(*narrow_down_dictionaries(5))"],"metadata":{"id":"0qpvW8mLifuk","outputId":"5cfe1d43-5298-42fb-a0a3-51c11e7924ae"}},{"cell_type":"markdown","source":["As it is observed, narrowing-down by 5%  increased accuracies of Unigram models by around 2%, whereas it decreased accuracies of Bigram models by around 2%.\n","\n","We can safely say that, around 5% of the old vocabulary Unigrams were insignificant/non-useful (and in fact overfitting) for classification.\n","\n","Yet, for Bigrams, we still seem to be eliminating too many. We should not have seen a decrease in accuracy. Let us try narrowing with only 2%.\n"],"metadata":{"collapsed":false,"id":"aF8Zw6Gpiful"}},{"cell_type":"markdown","source":["#### Classification with 2% Narrowed-Down Dictionaries"],"metadata":{"collapsed":false,"id":"cQmtPeo3iful"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["UNIGRAM   --------- --   UNIGRAM   ------- ----   UNIGRAM   ------------   UNIGRAM   ------------   UNIGRAM   -----\n","\n","- - - -  UNIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 41), ('entertainment', 33), ('politics', 69), ('sport', 62), ('tech', 93)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.812\n","\n","- - - -  UNIGRAMS.  UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 45), ('entertainment', 32), ('politics', 69), ('sport', 65), ('tech', 87)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.832\n","\n","\n","BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   ----\n","\n","- - - -  BIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 29), ('entertainment', 62), ('politics', 79), ('sport', 40), ('tech', 88)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.755\n","\n","- - - -  BIGRAMS.  UNIQUE Test Terms - - - -\n","\n","298  samples predicted  in   1  seconds \n","\n","Predicted:  OrderedDict([('business', 26), ('entertainment', 57), ('politics', 77), ('sport', 36), ('tech', 102)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.725\n","\n"]}],"source":["classify_all(*narrow_down_dictionaries(2))"],"metadata":{"id":"tNjR-V12iful","outputId":"9d0b6683-512f-43f4-d00d-ee31737006a2"}},{"cell_type":"markdown","source":["Compared to 5% narrowed version above, Accuracies of Unigram models are decreased by around 1%, yet Bigram has increased around 4%.\n","\n","It seems that, only around 2% of Bigram vocabulary is insignificant/overfitting, not as much as 5%.\n","\n","For Unigram Vocabulary, we observed that, definitely more than 2%, around 5%, definitely less than 20% of the Unigram vocabulary is insignificant."],"metadata":{"collapsed":false,"id":"3XdbjDBLiful"}},{"cell_type":"markdown","source":["One factor that effects all these Accuracy changes while narrowing-down the Dictionaries is how IDF is calculated.\n","There are different smoothing options in IDF.\n","We have chosen the most accurate option for our dataset after trying different options.\n","\n","        inverse_document_frequency = math.log(  5    /  how_many_categories_contain_this_term )        --> our choice: no smoothing\n","        inverse_document_frequency = math.log(  5    / (how_many_categories_contain_this_term +1) )\n","        inverse_document_frequency = math.log( (5+1) / (how_many_categories_contain_this_term +1) )\n","\n","With \"no smoothing\", the classification power of common words (especially stop-words) is reduced the most."],"metadata":{"collapsed":false,"id":"KwpALvbHiful"}},{"cell_type":"markdown","source":["# PART 3 : B\n","# Removing Stop Words\n"],"metadata":{"collapsed":false,"id":"zeMoDVKkiful"}},{"cell_type":"markdown","source":["### Listing the most effective Non-StopWords\n","\n","In Part-3-A: First Objective:  We analyzed the strongest Terms in terms of their effect on prediction, by calculating TF-IDF for all terms.\n","Now, we will do the same most-effective listing, while excluding Unigrams and Bigrams that include stop-words."],"metadata":{"collapsed":false,"id":"mwOBLV9-ifum"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Category:  SPORT    15 Most effective Non-Stop-WORDS:\n","['roddick', 'chelsea', 'coach', 'nadal', 'referee', 'athens', 'arsenal', 'tennis', 'championships', 'slam', 'indoor', 'gara', 'wenger', 'mourinho']\n","\n","Category:  BUSINESS    15 Most effective Non-Stop-WORDS:\n","['yukos', 'economy', 'lse', 'imf', 'deficit', 'gm', 'worldcom', 'ebbers', 'market', 'boerse', 'firms', 'securities', 'creditors', 'fiat']\n","\n","Category:  POLITICS    15 Most effective Non-Stop-WORDS:\n","['tory', 'tories', 'kilroy', 'ukip', 'lib', 'lords', 'chancellor', 'asylum', 'labour', 'mps', 'election', 'immigration', 'tax', 'party']\n","\n","Category:  ENTERTAINMENT    15 Most effective Non-Stop-WORDS:\n","['album', 'actress', 'festival', 'film', 'oscar', 'chart', 'aviator', 'awards', 'movie', 'comedy', 'elvis', 'theatre', 'oscars', 'nominated']\n","\n","Category:  TECH    15 Most effective Non-Stop-WORDS:\n","['software', 'users', 'spam', 'microsoft', 'gadgets', 'mobiles', 'portable', 'bt', 'digital', 'consumers', 'viruses', 'blogs', 'xbox', 'p2p']\n","\n","\n","Category:  SPORT    Most effective Non-Stop-BIGRAMs:\n","['grand slam', 'australian open', 'davis cup', 'champions league', 'olympic champion', 'cross country', 'second half', 'half time', 'bbc sport', 'fly half', 'french open', 'real madrid', 'anti doping', 'drugs test']\n","\n","Category:  BUSINESS    Most effective Non-Stop-BIGRAMs:\n","['stock market', 'mr glazer', 'analysts said', 'deutsche boerse', 'oil prices', 'mr ebbers', 'consumer spending', 'economic growth', 'fannie mae', 'fourth quarter', 'retail sales', 'house prices', 'mr sullivan', 'chief economist']\n","\n","Category:  POLITICS    Most effective Non-Stop-BIGRAMs:\n","['kilroy silk', 'michael howard', 'mr blair', 'liberal democrats', 'home secretary', 'mr brown', 'mr kennedy', 'lib dems', 'mr kilroy', 'mr howard', 'labour party', 'blair said', 'lib dem', 'council tax']\n","\n","Category:  ENTERTAINMENT    Most effective Non-Stop-BIGRAMs:\n","['vera drake', 'best actress', 'named best', 'best director', 'million dollar', 'dollar baby', 'best actor', 'film festival', 'academy awards', 'best supporting', 'band aid', 'best film', 'box office', 'golden globe']\n","\n","Category:  TECH    Most effective Non-Stop-BIGRAMs:\n","['high definition', 'wi fi', 'mac mini', 'consumer electronics', 'file sharing', 'digital cameras', 'music players', 'net users', 'mobile phone', 'anti virus', 'camera phones', 'cash machines', 'mr dean', 'said mr']\n"]}],"source":["\"\"\" UNIGRAM \"\"\"\n","for m, category_words_to_tfidf in enumerate(tfidf_for_unigrams_in_categories):\n","\n","    print(\"Category:  \" + categories[m].upper() + \"    15 Most effective Non-Stop-WORDS:\")\n","\n","    tfidf_sorted_words = dict(sorted(category_words_to_tfidf.items(), key = itemgetter(1), reverse = True))\n","    most_effective_15_words = []\n","    k = 0\n","    for word_ in tfidf_sorted_words.keys():\n","        if word_ not in ENGLISH_STOP_WORDS:\n","            most_effective_15_words.append(word_)\n","            k += 1\n","        if k==14:\n","            break\n","    print(str(most_effective_15_words) + \"\\n\")\n","\n","\n","\"\"\" BIGRAM \"\"\"\n","for m, category_bigrams_to_tfidf in enumerate(tfidf_for_bigrams_in_categories):\n","\n","    print(\"\\nCategory:  \" + categories[m].upper() + \"    Most effective Non-Stop-BIGRAMs:\")\n","\n","    tfidf_sorted_bigrams = dict(sorted(category_bigrams_to_tfidf.items(), key = itemgetter(1), reverse = True))\n","    most_effective_bigrams = []\n","    k = 0\n","    for bigram_ in tfidf_sorted_bigrams.keys():\n","        bigram = bigram_.split()\n","        if (bigram[0] not in ENGLISH_STOP_WORDS) and (bigram[1] not in ENGLISH_STOP_WORDS):\n","            most_effective_bigrams.append(bigram_)\n","            k += 1\n","        if k==14:\n","            break\n","    print(most_effective_bigrams)"],"metadata":{"id":"IWE6mKtYifum","outputId":"4b370147-3a30-4010-ff59-181685ca25f8"}},{"cell_type":"markdown","source":["Since the most high-relevance Unigrams (words) were already non-stop words, we see no change in this part, from the Part-3-A.\n","This is expected, since stop words are common between all categories, reducing their IDF scores.\n","\n","On the other hand, most effective non-stop-Bigrams in this, look very different from their Part-3-A counterparts.\n","It appears that, in our dataset, Bigrams that include stop words have higher TF-IDF scores than non-stop ones.\n","This is no big surprise, since in English, compound words and phrasal verbs has a major importance in conveying meaning.\n"],"metadata":{"collapsed":false,"id":"TYDQ4rzRifum"}},{"cell_type":"markdown","source":["### Removing Stop Words from Vocabulary\n","\n","Create new dictionaries from old ones, excluding Unigrams or Bigrams that include stop-words."],"metadata":{"collapsed":false,"id":"4G67jpgBifum"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def obtain_non_stop_vocabulary():\n","\n","    \"\"\" UNIGRAM \"\"\"\n","    non_stop_unigram_dictionaries = []\n","    for category_dictionary in dictionaries_unigram:\n","        category_non_stop_dict = {word: category_dictionary.get(word) for word in category_dictionary if word not in ENGLISH_STOP_WORDS}\n","        non_stop_unigram_dictionaries.append(category_non_stop_dict)\n","\n","    \"\"\" BIGRAM \"\"\"\n","    non_stop_bigram_dictionaries = []\n","    for category_dictionary in dictionaries_bigram:\n","        category_non_stop_dict = {}\n","        for bigram__ in category_dictionary.keys():\n","            bigram___ = bigram__.split()\n","            if (bigram___[0] not in ENGLISH_STOP_WORDS) and (bigram___[1] not in ENGLISH_STOP_WORDS):\n","                category_non_stop_dict[bigram__] = category_dictionary.get(bigram__)\n","        non_stop_bigram_dictionaries.append(category_non_stop_dict)\n","\n","    return non_stop_unigram_dictionaries, non_stop_bigram_dictionaries"],"metadata":{"id":"XQWx581gifum"}},{"cell_type":"markdown","source":["### Classification with Stop-Word-Free Vocabulary"],"metadata":{"collapsed":false,"id":"0T8ESey6ifun"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["UNIGRAM   --------- --   UNIGRAM   ------- ----   UNIGRAM   ------------   UNIGRAM   ------------   UNIGRAM   -----\n","\n","- - - -  UNIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 48), ('entertainment', 43), ('politics', 69), ('sport', 62), ('tech', 76)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.869\n","\n","- - - -  UNIGRAMS.  UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('business', 49), ('entertainment', 39), ('politics', 73), ('sport', 64), ('tech', 73)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.866\n","\n","\n","BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   -------------   BIGRAM   ----\n","\n","- - - -  BIGRAMS.  NON-UNIQUE Test Terms  - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('entertainment', 26), ('politics', 50), ('tech', 222)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.419\n","\n","- - - -  BIGRAMS.  UNIQUE Test Terms - - - -\n","\n","298  samples predicted  in   0  seconds \n","\n","Predicted:  OrderedDict([('entertainment', 22), ('politics', 49), ('tech', 227)])\n","Actual:  :  OrderedDict([('business', 67), ('entertainment', 55), ('politics', 55), ('sport', 69), ('tech', 52)])\n","\n"," ACCURACY:  0.409\n","\n"]}],"source":["classify_all(*obtain_non_stop_vocabulary())"],"metadata":{"id":"0aCdPgggifun","outputId":"228adae4-d57b-4791-9434-e0a5ee43dc52"}},{"cell_type":"markdown","source":["##### Unigrams\n","Removing Stop Words has increased Unigram model Accuracies by 6% and %3 (non-unique and unique models respectively), reaching both 86%.\n","It makes sense to eliminate Stop Words since they are very common words with high frequencies. They have no meaning by themselves, thus not related to any topic or category; they only clutter the vocabulary and mislead the prediction.\n","\n","<br/>\n","\n","##### Bigrams\n","Bigram results are terrible, there is no sample classified for Sport or Business categories. Yet, this is expected.\n","Reason is that, stop words were a part of many Bigrams that are significant in classification.\n","Having many Bigrams removed, some categories had no enough vocabulary to classify accurately.\n","For that reason, it is not useful to remove Stop Words from Bigram vocabulary. Many Bigrams contain Stop Words.\n","English, as a natural language, builds sentence structures and meaning with a lot of help from Stop Words."],"metadata":{"collapsed":false,"id":"yannN9ikifun"}},{"cell_type":"markdown","source":["# PART 4\n","\n","# Comparison of All Vocabulary Variations"],"metadata":{"collapsed":false,"id":"lQHDjFdLifun"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\n","------     ACCURACY    for Model and Vocabulary Variations  ------\n"]},{"data":{"text/plain":"                                  Part2: Full Dictionary  20 % Narrowed  \\\nUNIGRAMS.  NON-UNIQUE Test Terms                    0.81           0.76   \nUNIGRAMS.      UNIQUE Test Terms                    0.84           0.81   \nBIGRAMS.   NON-UNIQUE Test Terms                    0.73           0.70   \nBIGRAMS.       UNIQUE Test Terms                    0.71           0.68   \n\n                                  5 % Narrowed  2 % Narrowed  \\\nUNIGRAMS.  NON-UNIQUE Test Terms          0.83          0.81   \nUNIGRAMS.      UNIQUE Test Terms          0.84          0.83   \nBIGRAMS.   NON-UNIQUE Test Terms          0.70          0.76   \nBIGRAMS.       UNIQUE Test Terms          0.69          0.72   \n\n                                  Stop-Words Removed  \nUNIGRAMS.  NON-UNIQUE Test Terms                0.87  \nUNIGRAMS.      UNIQUE Test Terms                0.87  \nBIGRAMS.   NON-UNIQUE Test Terms                0.42  \nBIGRAMS.       UNIQUE Test Terms                0.41  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Part2: Full Dictionary</th>\n      <th>20 % Narrowed</th>\n      <th>5 % Narrowed</th>\n      <th>2 % Narrowed</th>\n      <th>Stop-Words Removed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>UNIGRAMS.  NON-UNIQUE Test Terms</th>\n      <td>0.81</td>\n      <td>0.76</td>\n      <td>0.83</td>\n      <td>0.81</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>UNIGRAMS.      UNIQUE Test Terms</th>\n      <td>0.84</td>\n      <td>0.81</td>\n      <td>0.84</td>\n      <td>0.83</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>BIGRAMS.   NON-UNIQUE Test Terms</th>\n      <td>0.73</td>\n      <td>0.70</td>\n      <td>0.70</td>\n      <td>0.76</td>\n      <td>0.42</td>\n    </tr>\n    <tr>\n      <th>BIGRAMS.       UNIQUE Test Terms</th>\n      <td>0.71</td>\n      <td>0.68</td>\n      <td>0.69</td>\n      <td>0.72</td>\n      <td>0.41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"output_type":"display_data"}],"source":["print(\"\\n------     ACCURACY    for Model and Vocabulary Variations  ------\")\n","\n","rows = [[0,4,8,12,16], [1,5,9,13,17], [2,6,10,14,18], [3,7,11,15,19]]\n","for row_ in range(4):\n","    for i_ in range(5):\n","        rows[row_][i_] = accuracies[rows[row_][i_]]\n","\n","recall_table = pd.DataFrame(rows, columns = ['Part2: Full Dictionary','20 % Narrowed','5 % Narrowed','2 % Narrowed','Stop-Words Removed'])\n","recall_table.index = ['UNIGRAMS.  NON-UNIQUE Test Terms', 'UNIGRAMS.      UNIQUE Test Terms', 'BIGRAMS.   NON-UNIQUE Test Terms', 'BIGRAMS.       UNIQUE Test Terms']\n","\n","display(recall_table.head())"],"metadata":{"id":"4hL37nhZifun","outputId":"60a848c6-b560-40d4-e9af-ec7864ea0b0b"}},{"cell_type":"markdown","source":["#### Previously calculated:\n","<img src=\"data:image/png;base64,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\" width=\"1000\">"],"metadata":{"collapsed":false,"id":"gGmG9ckrifuo"}},{"cell_type":"markdown","source":["### Stop Words\n","\n","The best Vocabulary Model is the Stop-Words Removed Unigram vocabularies, with 87 % Accuracy.\n","Assuming stop words generally reduce performance; we could guess that,\n","for Unigram Dictionaries, stop-words constitutes around 5 to 10 % of the vocabulary.\n","for Bigram Dictionaries,  stop-words are included in more than 25% of the vocabulary.\n","<br/>\n","\n","### Reduce Test Samples to Unique terms or Not ?\n","\n","NON-UNIQUE: Looping over (calculating and summing up) Probability for EACH Term in Test sample one-by-one.\n","This way, a Term appears more frequently has more affect than another one that appears once.\n","As seen in results, this is not advantageous, since Unique words can be better classifiers than frequent ones.\n","\n","UNIQUE: Looping over not EACH but Each UNIQUE Term in Test sample.\n","This approach generally has at least 2 % more Accuracy advantage in Unigram Dictionaries.\n","Yet, for Bigram Vocabularies, it is the opposite.\n","<br/>\n","\n","### How much Narrowing-Down the Vocabularies (removing TF-IDF-wise insignificant terms from Dictionaries) ?\n","\n","We would like to see if removing non-category-relevant terms from dictionaries can reduce overfitting and errors, and improve performance.\n","Both for Unigram and Bigram Vocabularies, narrowing down by 20 % too much, we lost useful terms too, since all accuracies are observed to be decreased.\n","\n","As it is observed, narrowing-down by 5%  increased accuracies of Unigram models by around 2%, whereas it decreased accuracies of Bigram models by around 2%.\n","We can safely say that, around 5% of the old vocabulary Unigrams were insignificant/non-useful (and in fact overfitting) for classification.\n","Yet, for Bigrams, we still seem to be eliminating too many. We should not have seen a decrease in accuracy.\n","\n","Compared to 5% narrowed version, Accuracies of Unigram models are decreased by around 1%, yet Bigram has increased around 4%.\n","It seems that, only around 2% of Bigram vocabulary is insignificant/overfitting, not as much as 5%.\n","For Unigram Vocabulary, we observed that, definitely more than 2%, around 5%, definitely less than 20% of the Unigram vocabulary is insignificant.\n","\n","<br/>\n","\n","### Unigram vs Bigram:\n","\n","Before the experiments, we would expect bigrams (word pairs) to perform better than unigrams (individual words) since\n","for example \"best actress\" or \"digital cameras\" are more specific classifiers in our daily language than \"best\" \"actress\" \"digital\" \"cameras\".\n","Yet our experiment results has shown higher accuracies in Unigram models.\n","Reason could be that, since our dataset is small, Bigrams were too unique for each article, an article could not have enough common bigrams with another article in the same category.\n","<br/>\n","\n","### Why only 87% Accuracy ? :\n","\n","In our previous experiments with KNN and Decision Tree algorithms, we could see accuracies around 90-95%. In this Naive Bayes experiment we could see max 85% accuracy with the best model. We of course could have made errors while constructing algorithms; the dataset could also contain errors and outliers; yet we believe even though Naive Bayes is a very fast algorithm, it is not very accurate. Reason is that, it only depends on the past, and heuristically guesses if similar events will happen in the future. The actual issue with that is, Naive Bayes assumes \"conditional independence\" and \"equal chance\"; it does not consider that events such as some words appearing together (not necessarily adjacent) in an article can be depending on each other, it does not consider that presence of some words might be more important than others.\n"],"metadata":{"collapsed":false,"id":"KmK2r2X8ifuo"}},{"cell_type":"markdown","source":["#### This is the end of our report."],"metadata":{"collapsed":false,"id":"EljIEFBtifuo"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}